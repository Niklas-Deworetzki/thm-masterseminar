
\section{Partial Evaluation}\label{sec:partial-evaluation}

In this chapter, we dive deeper into the inner workings and implementation details of partial evaluators.
The previous chapters already covered the operational mode of partial evaluators on a larger scale.
Thus, we already know that a partial evaluator accepts a source program as well as some fixed inputs to the source program as its own input and produces a residual output consisting of computations that cannot be evaluated under the given static input.

During specialization a partial evaluator will analyze the components of a program, that represent computations.
While the specific components are dependent on the programming language used for the input program, a partial evaluator will usually work on expressions and statements, as well as the definitions accompanying them.
Consequently a partial evaluator manages information about known names (such as the fixed inputs) and transforms the present components during specialization.
This way, redundant computations are removed or the structure of statements or expressions is simplified using the known information.

This chapter will give an overview of different methods, that can be used to perform computations given some static input.
These methods act as instruments for a partial evaluator, to optimize a program during specialization.
Afterwards it is explained, how a partial evaluator can decide, which computations can be performed statically and which have to be present in the residual program.


\subsection{Instruments of Partial Evaluation}\label{sec:pe-instruments}

In the following, we will see different available techniques, that allow partial evaluators to compute static values or expressions containing (at least some) static values.
Partial evaluation is mainly based on the propagation and removal of statically known data.
Since initially only parts of the input of a source program are known as static data, this is the only way a partial evaluator is able to analyze and optimize an entire program.
\cite[Chap. 1]{Jones_PartialEvaluation}~mentions three main techniques, which are discussed further next: symbolic computation, unfolding of function calls and program point specialization.

\subsubsection*{Symbolic Computation}

Symbolic computation can be used as an optimization technique in a partial evaluator.
The essence of symbolic computation as an optimization technique is to use the structure of an expression, to simplify and thus optimize it.
Under this aspect, we also consider performed computations as well as constant folding, constant propagation and their subfields (e.g.\ sparse constant propagation, which is based on conditionals).
Symbolic computation represents a powerful technique since it is not only possible to evaluate completely constant expressions, but also simplify expressions that are based on constants.

As an example consider Listing~\ref{lst:symbolic-computation}.
If the input \texttt{x} of function \texttt{f} was fixed as \texttt{x = 1}, a partial evaluator could generate a specialized function \texttt{f1} as part of a residual program.
The original function contains two multiplications, one addition as well as one division and one subtraction, while the specialized function contains only a single multiplication operation.
This optimization is achieved by applying the aforementioned patterns:

\begin{enumerate}
\item Replacing the variable \texttt{x} with the fixed value of \texttt{1} yields the following expression as an intermediate result: \texttt{y / (1 - 2) + 3 * 1 * y}.
\item The constant subexpressions \texttt{3 * 1} and \texttt{1 - 2} can be evaluated using constant folding, resulting in the new expression \texttt{y / (-1) + 3 * y}.
\item The division \texttt{y / (-1)} can be simplified to \texttt{-y} since \texttt{1} represents the neutral element of division, resulting in the expression \texttt{-y + 3 * y}.
\item Finally symbolic computation allows us to simplify this expression into \texttt{2 * y}.
\end{enumerate}

\begin{lstlisting}[language=scala,caption={Definition of a simple function and its specialization.},label={lst:symbolic-computation}]
  def f(x: Int, y: Int): Int =
    y / (x - 2) + 3 * x * y

  def f1(y: Int): Int =
    2 * y
\end{lstlisting}


\subsubsection*{Unfolding Function Calls}

The unfolding of function calls (also known as \textit{inlining}) is a comparatively simple technique, that allows for optimizations to be applied beyond limits of a single function.
When unfolding a function call, the body of the called function is simply inserted at call position renaming occurring variables according to the function's parameters.

Listing~\ref{lst:unfolding} shows an example of a function that is specialized and optimized by unfolding its recursive calls.
Unfolding introduces the whole expression inside the function's body into the initial expression, where the parameter is consistently renamed with\linebreak \texttt{(n - 1)}.
This introduces another recursive call with parameter \texttt{(n - 2)}, which unfolded introduces another recursive call, etc.

If applied without care, this scheme can result in infinite loops.
While in this example it is possible to terminate the recursive unfolding if the condition within the recursive expression is evaluated, more complex functions are not guaranteed to terminate.
This example also shows, that optimization schemes can be combined to yield even more optimized results, as the resulting expression could be reduced even further using constant folding.

\begin{lstlisting}[language=scala,caption={Definition of the \texttt{factorial} function and its specialization.},label={lst:unfolding}]
  def factorial(n: Int): Int =
    if (n == 0) 1
    else n * factorial(n - 1)

  def factorial3(): Int =
    3 * (3 - 1) * (3 - 2) * 1
\end{lstlisting}


\subsubsection*{Program Point Specialization}

Program point specialization describes a technique to specialize functions as part of a larger program.
Especially in larger programs, a function may be called multiple times with the same fixed partial inputs.
Instead of generating a new function definition for each occurrence or unfolding every call, it may be preferred to extract a shared function definition to minimize code size.
Listing~\ref{lst:pps} shows the specialization of Ackermann's function with the fixed input \texttt{n = 2} as an example, while also applying the previously mentioned optimization strategies.

\begin{lstlisting}[language=scala,caption={Definition of the \texttt{ackermann} function and its specialization.},label={lst:pps}]
  def ack(n: Int, m: Int): Int =
    if (m == 0) n + 1
    else if (n == 0) a(m - 1, 1)
    else a(m-1, a(m, n-1))

  def ack2(n: Int): Int =
    if (n == 0) 3
    else a1(a2(n - 1))

  def ack1(n: Int): Int =
    if (n == 0) 2
    else a1(n - 1)
\end{lstlisting}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../paper"
%%% End:
